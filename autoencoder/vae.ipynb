{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational autoencoder\n",
    "\n",
    "Example architecture:\n",
    "![Alt text](imgs/image-3.png)\n",
    "\n",
    "#### What: \n",
    "- a neural network that learns to predict its input data \n",
    "\n",
    "- encoder: encode its input into a lower dimension representation space\n",
    "\n",
    "    - where representation space / layer is sampled from probability distributions (eg. gaussian, multinomial) modelled for each dimension of the rep space \n",
    "\n",
    "\n",
    "- decoder: decodes the sampled representation space / layer to get the output \n",
    "\n",
    "- model learns by minimising difference between input and output\n",
    "\n",
    "- For example: \n",
    "    - input: cat image (28*28)\n",
    "    - encoder encodes input into (4) dimension representation: \n",
    "        - eg. fur, size, species, ears\n",
    "        - 4D vector (representation space / vector layer) sampled from estimated prob distribution for each dimensional space\n",
    "    - output: decoder predicted cat image (28*28) \n",
    "\n",
    "#### So what: \n",
    "- achieves regularisation for dimension reduction via non-linear mapping to a lower dimension space modelled with prior distributions\n",
    "\n",
    "#### How: \n",
    "- using variational inference (optimisation by estimating parameters of proxy distributions) to learn representation space \n",
    "    - encoder learns representation space (z ~ p(z|x)) by estimating optimal parameters for the probability distribution of each dimension p(z|x) = p(x|z)p(z)\n",
    "    - encoder produces final representation vector layer z by sampling from each probability distribution of each dimension\n",
    "\n",
    "- model: \n",
    "    - encoder (function)\n",
    "    - prior distributions\n",
    "    - decoder (inverse function)\n",
    "    - output layer (depending on required output format)\n",
    "- loss function: \n",
    "    - mse\n",
    "    - cross entropy (?)\n",
    "\n",
    "\n",
    "#### Why / Why not : \n",
    "- Non-deterministic representation \n",
    "- Regularisation / Inductive bias: 'prior distributions' p(z) act as our prior belief about how the input data distributes yet also a way to introduce regularisation / smoothen representation learned\n",
    "\n",
    "- Extension: \n",
    "    - Introducing Disentanglement in VAE: to further ensure independence between dimensions in representation space\n",
    "\n",
    "Reference: \n",
    "https://www.youtube.com/watch?v=WYrvh50yu6s&t=1324s (example taken from here)\n",
    "\n",
    "Further reading: \n",
    "vae paper: https://arxiv.org/pdf/1312.6114.pdf\n",
    "variational inference: https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: \n",
    "\n",
    "Reparameterisation trick: \n",
    "- ref: https://www.youtube.com/watch?v=vy8q-WnHa9A\n",
    "\n",
    "Why/challenge: \n",
    "- unable to do backpropagation on loss function with unknown parameters/expectation of probability distribution (eg. optimal parameters of probability distribution of z are unknown in vae)\n",
    "    \n",
    "- hence the need to remove stochasticity to enable backpropagation\n",
    "\n",
    "What: The trick for sampling z from z~N(miu, sigma) where miu and sigma is unknown, is to parameterise miu and sigma using another parameter (epsilon) which follows a known distribution\n",
    "\n",
    "How - intuition: \n",
    "![Alt text](image.png) \n",
    "![Alt text](image-1.png)\n",
    " \n",
    "\n",
    "Derivation (why it works)\n",
    "- TODO: \n",
    "- (Leibniz integral rule)\n",
    "\n",
    "Notes: \n",
    "- reparameterisation: (parameterising a distribution w known a using another distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In what sense is unknown prob dist parameters a problem for backpropagation? (to review derivation): \n",
    "    - problem is that f(x) follows a distribution with unknown parameters hence we substitute f(x) with g(eps); where eps follows a known distribution - eps ~ N(0, 1)\n",
    "    - qn: but how does this help in backprop, isnt backprop still seeking to estimate the parameters? / introduction of eps allows miu and sigma to vary and hence be optimised?\n",
    "\n",
    "- how come its sufficient to only parameterise sigma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation v0: \n",
    "- ref: https://www.youtube.com/watch?v=VELQT1-hILo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "# img -> hidden dim -> mean, std -> parameterisation trick (for sampling) -> decoder -> output img\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, h_dim=200, z_dim=20): \n",
    "        super().__init__()\n",
    "        # encoder\n",
    "        self.img_2hid = nn.Linear(input_dim, h_dim)\n",
    "        self.hid_2mu = nn.Linear(h_dim, z_dim)\n",
    "        self.hid_2sigma = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "        # decoder\n",
    "        self.z_2hid = nn.Linear(z_dim, h_dim)\n",
    "        self.hid_2img = nn.Linear(h_dim, input_dim)\n",
    "\n",
    "        self.relu = nn.ReLU() #inplace ? \n",
    "\n",
    "    def encode(self, x):\n",
    "        #hidden layer \n",
    "        h = self.relu(self.img_2hid(x))\n",
    "        #parameters: miu, sigma \n",
    "        mu, sigma = self.hid_2mu(h), self.hid_2sigma(h)\n",
    "        return mu, sigma\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = self.relu(self.z_2hid(z))\n",
    "        # ensure output range similar to input range\n",
    "        pred_x = torch.sigmoid(self.hid_2img(h))\n",
    "        return pred_x\n",
    "\n",
    "    def forward(self, x): \n",
    "        # encode\n",
    "        mu, sigma = self.encode(x)\n",
    "        # sampling using reparametrisation\n",
    "        # return random values w mean, var [0, 1]\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z_reparameterised = mu + sigma*epsilon\n",
    "        # decode\n",
    "        x_reconstructed = self.decode(z_reparameterised)\n",
    "\n",
    "        # return values to be optimised for: \n",
    "        # mse: x vs x_reconstructed\n",
    "        # kl divergence: mu, sigma vs gaussian\n",
    "        return x_reconstructed, mu, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 28*28)\n",
    "vae = VariationalAutoEncoder(input_dim=784)\n",
    "# how is it that this konws which method to run?\n",
    "print(len(vae(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop to test model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
