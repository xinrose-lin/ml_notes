{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "\n",
    "#### What: \n",
    "- a neural network that learns to predict its input data\n",
    "- by encoding its input into a lower dimension representation space / vector layer\n",
    "- then decoding the representation space / vector layer to get the output \n",
    "- model learns by minimising difference between input and output\n",
    "\n",
    "#### So what: \n",
    "- achieves dimension reduction via non-linear mapping to a lower dimension space\n",
    "\n",
    "#### How: \n",
    "- intuition: learning neural network with lower dimensions in the central hidden layers\n",
    "- model architecture:\n",
    "    - encoder (function)\n",
    "    - decoder (inverse function)\n",
    "    - output layer (depending on required output format)\n",
    "- loss function: \n",
    "    - mse\n",
    "    - cross entropy (?)\n",
    "\n",
    "\n",
    "#### Why / Why not : \n",
    "- Deterministic representation \n",
    "- Extension: Variational autoencoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- How does changing the layers result in differing results \n",
    "    - deeper layers - diff between going from [28*28 to 16] vs gradually.. - is this a matter of bias vs variance?\n",
    "    - layers with lesser neurons - greater dimension reduction, results in more global/generalised learning? \n",
    "- (Optim) What is the adam optimiser: a method for stochastic optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "ref: https://www.youtube.com/watch?v=c36lUUr864M&t=2080s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # to transform image into torch tensor\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(), \n",
    "#     transforms.Normalize((0.5), (0.5)) # output = (input - mean) / std\n",
    "# ])\n",
    "\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# returns tuple (image, target class)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_data, \n",
    "                                          batch_size=64, \n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x16af6e530>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(data_loader)\n",
    "# dataloader class / object \n",
    "# <torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x16af6f910>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(data_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(torch.min(images), torch.max(images))\n",
    "# to note the numerical range of image data \n",
    "# to use sigmoid function at the end: \n",
    "# set [min, max] = [0, 1]\n",
    "# to use tanh: \n",
    "# set [min, max] = [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        # ought to first initialise the super class\n",
    "        super().__init__()\n",
    "        # N (batch_size), 28*28\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 12), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(12, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(12, 64), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid() \n",
    "            # to correspond with input image range\n",
    "        )\n",
    "\n",
    "    # inference?\n",
    "    def forward(self, x):\n",
    "        encoder = self.encoder(x)\n",
    "        decoded = self.decoder(encoder)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "\n",
    "model = Autoencoder()\n",
    "# loss function = mse\n",
    "criterion = nn.MSELoss()\n",
    "# TODO: what is the adam optimiser: \n",
    "# a method for stochastic optimisation\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=1e-3, \n",
    "                             weight_decay=1e-5)\n",
    "# weight decay - l2 regularisation on the neural network weights\n",
    "# to keep nn weights small \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.0429\n",
      "Epoch:2, Loss:0.0360\n",
      "Epoch:3, Loss:0.0337\n",
      "Epoch:4, Loss:0.0383\n",
      "Epoch:5, Loss:0.0362\n",
      "Epoch:6, Loss:0.0311\n",
      "Epoch:7, Loss:0.0367\n",
      "Epoch:8, Loss:0.0370\n",
      "Epoch:9, Loss:0.0387\n",
      "Epoch:10, Loss:0.0360\n"
     ]
    }
   ],
   "source": [
    "# Training loop \n",
    "\n",
    "num_epochs = 10\n",
    "outputs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for (img, _) in data_loader: \n",
    "        img = img.reshape(-1, 28*28) #784\n",
    "        recon = model(img)\n",
    "        loss = criterion(recon, img)\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
